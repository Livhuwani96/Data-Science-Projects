{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqt_yzRy16Wj"
   },
   "source": [
    "## Compulsory Task \n",
    "\n",
    "In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries successfully imported.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Libraries successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vBP3WN2O16Wp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>United States/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>Britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>Britain/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   store_name         store_email  department  \\\n",
       "0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n",
       "1   2          Nordson Corporation                 NaN       Tools   \n",
       "2   3        Stag Industrial, Inc.                 NaN      Beauty   \n",
       "3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n",
       "4   5  Mercantile Bank Corporation                 NaN        Baby   \n",
       "\n",
       "         income date_measured          country  \n",
       "0  $54438554.24      4-2-2006   United States/  \n",
       "1  $41744177.01      4-1-2006          Britain  \n",
       "2  $36152340.34     12-9-2003    United States  \n",
       "3   $8928350.04      8-5-2006         Britain/  \n",
       "4  $33552742.32     21-1-1973   United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up store_income_data.csv\n",
    "store_income_df = pd.read_csv(\"store_income_data_task.csv\")\n",
    "store_income_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItqLwumA16Wr"
   },
   "source": [
    "1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sLkzt4Hr16Wr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 unique countries before cleaning:\n",
      "\n",
      "['United States/' 'Britain' ' United States' 'Britain/' ' United Kingdom'\n",
      " 'U.K.' 'SA ' 'U.K/' 'America' 'United Kingdom' nan 'united states'\n",
      " ' S.A.' 'England ' 'UK' 'S.A./' 'ENGLAND' 'BRITAIN' 'U.K' 'U.K '\n",
      " 'America/' 'SA.' 'S.A. ' 'u.k' 'uk' ' ' 'UK.' 'England/' 'england'\n",
      " ' Britain' 'united states of america' 'UK/' 'SA/' 'SA' 'England.'\n",
      " 'UNITED KINGDOM' 'America.' 'S.A..' 's.a.' ' U.K'\n",
      " ' United States of America' 'Britain ' 'England' ' SA'\n",
      " 'United States of America.' 'United States of America/' 'United States.'\n",
      " 's. africasouth africa' ' England' 'United Kingdom '\n",
      " 'United States of America ' ' UK' 'united kingdom' 'AMERICA' 'America '\n",
      " 'UNITED STATES OF AMERICA' ' S. AfricaSouth Africa' 'america'\n",
      " 'S. AFRICASOUTH AFRICA' 'Britain.' '/' 'United Kingdom.' 'United States'\n",
      " ' America' 'UNITED STATES' 'sa' 'United States of America' 'UK '\n",
      " 'United States ' 'S. AfricaSouth Africa/' 'S.A.' 'United Kingdom/'\n",
      " 'S. AfricaSouth Africa ' 'S. AfricaSouth Africa.' 'S. AfricaSouth Africa'\n",
      " '.' 'britain']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in the 'country' column before cleaning\n",
    "countries_before_cleaning = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_before_cleaning)} unique countries before cleaning:\\n\")\n",
    "print(countries_before_cleaning)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 unique countries after converting to lowercase and stripping whitespace:\n",
      "\n",
      "['united states/' 'britain' 'united states' 'britain/' 'united kingdom'\n",
      " 'u.k.' 'sa' 'u.k/' 'america' nan 's.a.' 'england' 'uk' 's.a./' 'u.k'\n",
      " 'america/' 'sa.' '' 'uk.' 'england/' 'united states of america' 'uk/'\n",
      " 'sa/' 'england.' 'america.' 's.a..' 'united states of america.'\n",
      " 'united states of america/' 'united states.' 's. africasouth africa'\n",
      " 'britain.' '/' 'united kingdom.' 's. africasouth africa/'\n",
      " 'united kingdom/' 's. africasouth africa.' '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert the 'country' column to lowercase and remove any trailing white spaces\n",
    "store_income_df['country'] = store_income_df['country'].str.lower().str.strip()\n",
    "\n",
    "# Display unique values after converting to lowercase and stripping whitespace\n",
    "countries_after_lower_strip = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_after_lower_strip)} unique countries after converting to lowercase and stripping whitespace:\\n\")\n",
    "print(countries_after_lower_strip)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 unique countries after removing punctuation:\n",
      "\n",
      "['united states' 'britain' 'united kingdom' 'uk' 'sa' 'america' nan\n",
      " 'england' '' 'united states of america' 's africasouth africa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Remove punctuation\n",
    "store_income_df['country'] = store_income_df['country'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "\n",
    "# Display unique values after removing punctuation\n",
    "countries_after_punctuation_removal = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_after_punctuation_removal)} unique countries after removing punctuation:\\n\")\n",
    "print(countries_after_punctuation_removal)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 unique countries after replacing missing values:\n",
      "\n",
      "['united states' 'britain' 'united kingdom' 'uk' 'sa' 'america' <NA>\n",
      " 'england' 'united states of america' 's africasouth africa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Replace different missing values with pd.NA\n",
    "store_income_df['country'] = store_income_df['country'].replace(['', 'nan', 'none', None, ' '], pd.NA)\n",
    "\n",
    "# Display unique values after replacing missing values\n",
    "countries_after_replacing_missing = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_after_replacing_missing)} unique countries after replacing missing values:\\n\")\n",
    "print(countries_after_replacing_missing)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with empty strings or whitespace-only strings in the 'country' column:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [id, store_name, store_email, department, income, date_measured, country]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check rows with empty strings or whitespace-only strings\n",
    "# If there are any empty rows,\n",
    "# We would need to remove them\n",
    "empty_rows = store_income_df[store_income_df['country'].isin(['', ' '])]\n",
    "print(\"Rows with empty strings or whitespace-only strings in the 'country' column:\\n\")\n",
    "print(empty_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6dcDc4P16Ws"
   },
   "source": [
    "2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qeV3CxMR16Ws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 unique countries after fuzzy matching:\n",
      "['United States' 'britain' 'United Kingdom' 'uk' 'sa' 'america' <NA>\n",
      " 'england' 'South Africa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of standard country names\n",
    "standard_countries = ['South Africa', 'United Kingdom', 'United States']\n",
    "\n",
    "# Function to match country names to standard names\n",
    "def match_country(country, choices):\n",
    "    if pd.isna(country):\n",
    "        return country\n",
    "    match, score = process.extractOne(country, choices)\n",
    "    if score >= 80:  # You can adjust the threshold for matching\n",
    "        return match\n",
    "    return country\n",
    "\n",
    "# Apply the matching function to the 'country' column\n",
    "store_income_df['country'] = store_income_df['country'].apply(lambda x: match_country(x, standard_countries))\n",
    "\n",
    "# Display unique values in the 'country' column after fuzzy matching\n",
    "countries_after_fuzzy_matching = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_after_fuzzy_matching)} unique countries after fuzzy matching:\")\n",
    "print(countries_after_fuzzy_matching)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 unique countries after mapping:\n",
      "['United States' 'United Kingdom' 'South Africa' <NA>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping of variations to the correct country names\n",
    "country_mapping = {\n",
    "    'britain': 'United Kingdom',\n",
    "    'uk': 'United Kingdom',\n",
    "    'sa': 'South Africa',\n",
    "    'america': 'United States',\n",
    "    'england': 'United Kingdom',\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'country' column\n",
    "store_income_df['country'] = store_income_df['country'].map(country_mapping).fillna(store_income_df['country'])\n",
    "\n",
    "# Display unique values in the 'country' column after mapping\n",
    "countries_after_mapping = store_income_df['country'].unique()\n",
    "print(f\"There are {len(countries_after_mapping)} unique countries after mapping:\")\n",
    "print(countries_after_mapping)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 unique countries after mapping (ignoring NaN):\n",
      "\n",
      "['United States' 'United Kingdom' 'South Africa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in the 'country' column after mapping, ignoring NaN\n",
    "countries_after_mapping = store_income_df['country'].dropna().unique()\n",
    "print(f\"There are {len(countries_after_mapping)} unique countries after mapping (ignoring NaN):\\n\")\n",
    "print(countries_after_mapping)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJZDMTwP16Ws"
   },
   "source": [
    "3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gMJbN84P16Wt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>2006-02-04</td>\n",
       "      <td>United States</td>\n",
       "      <td>6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>2003-09-12</td>\n",
       "      <td>United States</td>\n",
       "      <td>7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>2006-05-08</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>1973-01-21</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>18806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   store_name         store_email  department  \\\n",
       "0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n",
       "1   2          Nordson Corporation                 NaN       Tools   \n",
       "2   3        Stag Industrial, Inc.                 NaN      Beauty   \n",
       "3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n",
       "4   5  Mercantile Bank Corporation                 NaN        Baby   \n",
       "\n",
       "         income date_measured         country  days_ago  \n",
       "0  $54438554.24    2006-02-04   United States      6739  \n",
       "1  $41744177.01    2006-01-04  United Kingdom      6770  \n",
       "2  $36152340.34    2003-09-12   United States      7615  \n",
       "3   $8928350.04    2006-05-08  United Kingdom      6646  \n",
       "4  $33552742.32    1973-01-21  United Kingdom     18806  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'date_measured' to datetime format\n",
    "store_income_df['date_measured'] = pd.to_datetime(store_income_df['date_measured'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime(datetime.today())\n",
    "\n",
    "# Calculate the number of days ago\n",
    "store_income_df['days_ago'] = (current_date - store_income_df['date_measured']).dt.days\n",
    "\n",
    "# Display the DataFrame with the new 'days_ago' column\n",
    "store_income_df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
